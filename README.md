# D√©tection d'Account Takeover (ATO) ‚Äî Machine Learning avec scikit-learn (Python)

##  Objectif du projet
Ce projet vise √† **d√©tecter les tentatives de prise de contr√¥le de compte (Account TakeOver)** √† partir de logs d‚Äôauthentification utilisateur.  
Les donn√©es proviennent du dataset **RBA Dataset** de Kaggle, comprenant plus de **33 millions de lignes**, simulant des connexions l√©gitimes et malveillantes dans un contexte de cybers√©curit√©.
L‚Äôobjectif est de construire un **mod√®le robuste et interpr√©table** capable d‚Äôidentifier les comportements anormaux tout en limitant les faux positifs (FPR ‚âà 1%).

---

##  Stack technique
| Domaine                 | Outils |
|-------------------------|--------|
| Pr√©paration & analyse   | **Pandas**, **NumPy** |
| Mod√©lisation            | **scikit-learn** (MLPClassifier, Logistic Regression, XGBoost) |
| √âvaluation              | **PR-AUC**, **ROC-AUC**, **Recall@1%FPR**, matrice de confusion |
| Interpr√©tabilit√©        | **SHAP** |
| Visualisation           | **Matplotlib**,**Seaborn** |
| Environnement           | **Jupyter Notebook**, **Python 3.11** |

---

##  Jeu de donn√©es & √©chantillonnage
- **Source :** RBA Dataset (Kaggle) ‚Äî plus de **33 millions de connexions simul√©es** entre utilisateurs l√©gitimes et attaques ATO.
- **Objectif :** identifier les connexions frauduleuses √† partir des logs d‚Äôauthentification.
- **Sous-√©chantillon utilis√© (‚âà 300 000 lignes)** :
  - Conservation **de toutes les fraudes** (141 √©chantillons).
  - **√âchantillonnage al√©atoire de 1%** des connexions normales (~312 000).
  - Chargement progressif par **chunks de 200 000 lignes** pour √©viter la surcharge m√©moire.
- Cet √©chantillon est utilis√© **pour l‚Äôensemble des √©tapes** :  
  **EDA**, **pr√©traitement**, **feature engineering**, **mod√©lisation** et **interpr√©tabilit√©**.
- Le mod√®le final est calibr√© pour **1% de faux positifs (FPR)** et √©valu√© sur un **jeu de test distinct**.

---

##  M√©thodologie (6 √©tapes)

1) **Chargement & √©chantillonnage (~300k)**
   - **Conserver toutes les fraudes** et **√©chantillonner ~1%** des connexions normales.
   - Constituer un jeu de travail √©quilibr√© pour l‚ÄôEDA et l‚Äôentra√Ænement.

2) **Nettoyage & pr√©paration**
   - Contr√¥le du typage, d√©tection d‚Äôincoh√©rences et doublons.
   - Gestion des valeurs manquantes (imputation sobre + indicateurs de pr√©sence).
   - Regroupement des **cat√©gories rares** (ex. pays/devices) pour limiter la variabilit√©.
   - Mise √† l‚Äô√©chelle coh√©rente des variables num√©riques.

3) **EDA orient√©e risque**
   - Mesure de la **pr√©valence ATO** (globale & par segments : device, pays, cr√©neaux horaires).
   - Analyse des **comportements inhabituels** (ex. changement soudain de pays/device, d√©lais entre connexions).
   - Identification des **facteurs et patterns** corr√©l√©s au risque (r√©seau/ASN, RTT, succ√®s/√©chec login).
   - Formulation d‚Äôhypoth√®ses qui guident le feature engineering.

4) **Feature Engineering**
   - **Temporel** : rythme d‚Äôactivit√©, jour/heure, week-end.
   - **Comportement utilisateur** : transitions (nouveau pays/device/ASN), **d√©lai depuis la derni√®re connexion**.
   - **R√©seau** : signaux de latence/RTT et fournisseur (ASN).
   - **G√©ographie & device** : regroupements lisibles, r√©duction des modalit√©s rares.
   - Encodage des cat√©gorielles et harmonisation des √©chelles .

5) **Mod√©lisation & d√©s√©quilibre**
   - **Split stratifi√© 80/20** (train/test) et **pond√©ration des classes** pour compenser le fort d√©s√©quilibre.
   - **Benchmark de trois mod√®les :**
     - **R√©gression logistique** ‚Üí mod√®le **baseline** (lin√©aire, simple et interpr√©table).  
     - **XGBoost** ‚Üí mod√®le **arborescent**, robuste aux interactions complexes.  
     - **MLPClassifier** ‚Üí r√©seau de neurones **peu profond** (128‚Äì64 neurones) choisi comme **mod√®le final**.
   - S√©lection du meilleur compromis sur **PR-AUC**, **ROC-AUC** et **Recall@1%FPR**, adapt√©s au contexte de d√©tection rare.


6) **Optimisation, seuil & s√©lection finale**
   - Ajustements cibl√©s (r√©gularisation, taille du r√©seau, gestion des cat√©gories rares) pour **r√©duire l‚Äôoverfit**.
   - **Calibration du seuil m√©tier** sur **TRAIN** pour viser **~1% de faux positifs**, puis validation sur **TEST**.
   - **Interpr√©tabilit√©** : importance globale et impacts locaux (SHAP) pour expliciter les facteurs de risque.
   - **Export** des artefacts (pipeline + seuil + m√©ta) pour un usage reproductible.

---

##  R√©sultats principaux

| Indicateur | Train | Test |
|-------------|-------|------|
| **AUC-ROC** | 0.9949 | 0.9696 |
| **PR-AUC** | 0.7585 | 0.7092 |
| **Recall@1%FPR** | 0.991 | 0.893 |
| **Precision@1%FPR** | 0.037 | 0.042 |

> **Seuil choisi : 0.0191 (‚âà 1% de faux positifs)**  
> ‚Üí Bon √©quilibre entre rappel √©lev√© et faible taux de fausses alertes.

---

## Visualisations ‚Äî Analyse

| Graphique | Analyse |
|---|---|
| ![Courbe Precision‚ÄìRecall](screenshots/PR.png) | **AP ‚âà 0.709**, tr√®s au-dessus de la baseline ‚âà **0.00045** (pr√©valence).<br>Le mod√®le classe **tr√®s bien** les attaques malgr√© l‚Äôultra-d√©s√©quilibre.<br> √Ä **recall ‚âà 0.89**, la **precision ‚âà 3.7%** (co√ªt d‚Äôalerte acceptable pour du **screening large**). |
| ![Courbe ROC](screenshots/ROC.png) | **AUC ‚âà 0.97** (excellente s√©paration globale). Au point m√©tier **@ ~1% FPR**, on lit **TPR ‚âà 0.893**. |
| ![Matrice de confusion](screenshots/mat_confus.png) | Seuil calibr√© pour **~1% FPR** (Œ∏ ‚âà 0.0191).<br>**TP=25**, **FP=645**, **FN=3**, **TN=61 894** ‚áí<br> **Recall = 0.893**, **Precision = 0.037**, **FPR ‚âà 0.0103**.<br>Lecture m√©tier : on **capte presque toutes les fraudes** (3 manqu√©es) au prix d‚Äô**~645 alertes** √† v√©rifier. |
| ![SHAP summary](screenshots/shap.png) | Facteurs qui **poussent le score** : **ASN** (29695, 29492, 393398), **Country** (US/NO/PL/DE),<br> **Device Type** (mobile/desktop), **Login Successful**.<br>‚Üí Risque li√© aux **changements d‚Äôenvironnement** (r√©seau/appareil) et √† certains **fournisseurs**. |

---

##  Interpr√©tation SHAP

Les attributs les plus influents sur la d√©tection de fraude :
- **ASN (r√©seau d‚Äôorigine)** : certains ASN associ√©s √† des anomalies.
- **Login Successful** : indicateur cl√© d‚Äôacc√®s suspect.
- **Country (US, NO, PL, DE)** : importance g√©ographique dans la d√©tection.
- **Device Type** : diff√©rences notables entre mobile, desktop, tablet.

---

## üë§ Auteur

Projet r√©alis√© par **COMBO El-Fahad** ‚Äì Universit√© de Caen (2025).  
Contact : `el-fahad.combo@etu.unicaen.fr`

---

## üìÑ Licence

Ce projet est sous licence **MIT**. Voir le fichier `LICENSE`.
